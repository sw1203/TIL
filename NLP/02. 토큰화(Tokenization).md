# 토큰화(Tokenization)

## 말뭉치(Corpus)
    말뭉치 또는 코퍼스(Corpus)는 자연언어 연구를 위해 특정한 목적을 가지고 언어의 표본을 추출한 집합이다. - wikipedia
- 즉, 자연어 처리에 사용하는 방대한 양의 텍스트 데이터라고 생각하면 된다.
- 둘 이상의 코퍼스가 있으면 코포라(Corpora)라고 부름**

## Corpus 종류
1. **단일 언어 코퍼스:** 한 가지 언어로 구성된 코퍼스
2. **이중 언어 코퍼스:** 두 가지 언어로 구성된 코퍼스
3. **다중 언어 코퍼스:** 더 많은 종류의 언어로 구성된 코퍼스

## 토큰화(Tokenization)
- 주어진 corpus에서 token이라 불리는 단위로 나누는 작업
- **토큰:** 단위가 상황에 따라 다르지만, 보통 의미 있는 단위로 토큰을 정의
- 텍스트 토큰화는 **문장 토큰화**와 **단어 토큰화**로 구분할 수 있음

## 문장 토큰화(Sentence Tokenization)
- 토큰의 단위가 문장으로, 코퍼스 내에서 문장단위로 구분하는 작업으로 문장 분류(sentence segmentation)라고도 부름
- 일반적으로 ?나 온점(.)이나 ! 기준으로 문장을 구분하는데 이는 문제가 존재

    ex) IP 192.168.56.31 서버에 들어가서 로그 파일 저장 후 tkddnjs1203@gmail.com으로 보내줘. 그러고 카톡 줘.
    - 위의 예제에 온점을 기준으로 토큰화하면 원하는 결과를 얻을 수 없다.
    - 때문에 100% 정확하게 분리하는 것을 어려움
- 보통 널리 알려진 자연어 처리 툴킷인 NLTK에서 제공하는 영어 문장  토큰화 sent_tokenize를 사용

- Code
```{.python}
from nltk.tokenize import sent_tokenize
text= "Drug repositioning is to discover new uses of drugs. Text mining derives knowledge from unstructured text. We propose a method to predict new drug-disease relationships by taking into account the rate of frequency of genes simultaneously measured in disease-gene and gene-drug."
print(sent_tokenize(text))
```

- Output
![Sentence_Tokenize](https://github.com/sw1203/TIL/blob/master/Img/Sentence_Tokenize.PNG)


## 단어 토큰화(Word Tokenization)
